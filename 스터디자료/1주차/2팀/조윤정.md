# 1주차 과제 : Teachable Machine

## 새로운 캐릭터와 주제로 티쳐블 머신 실습하기

***
새로 고른 캐릭터 : 닮은 꼴로 유명한  __남도일 & 괴도키드__


![스내기 스터디_1주차 과제_ 06](https://user-images.githubusercontent.com/128327967/230076555-012cc894-65f8-4062-93e7-0a8897f17ba0.png)

![스내기 스터디_1주차 과제_07](https://user-images.githubusercontent.com/128327967/230075804-55e26215-7c0c-4b7e-8029-78b2fbd7d068.png)

![스내기 스터디_1주차 과제_03](https://user-images.githubusercontent.com/128327967/230076606-92074069-14bf-4f88-8504-5eabdf379f01.png)
>고난이도 문제는 학습량이 적어서 그런지 못 맞춘다
![스내기 스터디_1주차 과제_05](https://user-images.githubusercontent.com/128327967/230076589-e75e7dde-bafb-44ef-80b9-c007df1aad3f.png)

__~~짱구는 사실...~~__

> 결론
>> 키드와 남도일을 구분할 때 인공지능에게 큰 힌트가 될 수 있을 거 같은 머리카락 모양이나, 안경 같은 소품 등을 가린 테스트 샘플은 정확도가 떨어지는 것을 확인할 수 있었다. 
***
## epoch
> 훈련 데이터셋에 포함된 모든 데이터들이 한 번씩 모델을 통과할 때 epoch 1회이다. 
즉 __모든 학습 데이터셋을 학습하는 횟수를 의미__ 한다.
epoch가 100회라면, 학습 데이터 셋인 X를 100회 학습시켰다는 뜻이다.
 epoch가 클수록 효과적으로 학습하여 데이터 예측이 가능하다.
### batch size
> 영어 사전을 찾아보면 "(일괄적으로 처리되는) 집단",\
 "한 회분(한 번에 만들어내는 기계나 음식 등의 양)" 등이 있다. \
즉 __연산 한 번에 들어가는 데이터의 크기를 의미__ 한다.\
배치 사이즈가 커질수록 처리할 데이터양이 많아지기에 \
학습 속도가 느려지고, 메모리 부족 문제가 생길 수 있다.\
 그렇다고 너무 작은 경우엔 너무 적은 데이터를 대상으로 하면 훈련이 불안정해진다.
### 새로 알게 된 점
>epoch와 batch가 무엇인지 조사하는 과정에서 인공지능의 학습 과정을 얕게 학습할 수 있었다.\
 임의의 매개변수(가중치)를 정하고 이용해서 기울기를 계산하여 \
다음 가중치를 계속 업데이트 하는 과정을 거쳐서 기울기가 최소가 되게 하는 방법이었다. \
미적분을 배우는 당시에 인공지능 학습에도 쓰인다고 들은 기억이 있었는데, 이 과정을 말하는 것이 아니었을까 한다.
